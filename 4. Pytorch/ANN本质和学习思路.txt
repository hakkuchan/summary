ANN 本质上是一个函数，向 ANN 输入 X，它就会按照设定的规则（公式）计算出 y。

设计 ANN 本质上就是设计对 X 的计算规则，在 pytorch 中即是设置前向计算。

ANN 中的参数需要进行训练，才能高精度地计算出 y，训练地过程才需要用到反向计算。

所谓反向计算就是计算损失函数与 ANN 中参数的导数，即梯度。

再基于梯度大小按照一定规则（optimizer）更新 ANN 参数，反复迭代，直至损失函数低于期望值。

学习思路：学习不同 ANN，主要学习的是 ANN 的前向计算规则。至于反向计算的方法，尽管也是创新方向，目前还不必深究。

学习过程中，对于涉及的数学，只需搞懂数学运算对应的 pytorch 操作即可。

反过来，pytorch 的每一步操作，也要弄清其对应的数学公式是什么，应该用例子去验证。